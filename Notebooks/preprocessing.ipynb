{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135b24c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in /home/amon/anaconda3/lib/python3.8/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: torch==1.9.0 in /home/amon/anaconda3/lib/python3.8/site-packages (from torchaudio) (1.9.0)\r\n",
      "Requirement already satisfied: typing-extensions in /home/amon/anaconda3/lib/python3.8/site-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b548b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7eb1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import os\n",
    "\n",
    "class MetaCreate():\n",
    "    def __init__(self, transcription_path:str=r'/home/amon/Downloads/ALFFA_PUBLIC/ASR/SWAHILI/data/train/text', audio_path:str='/home/amon/Downloads/ALFFA_PUBLIC/ASR/SWAHILI/data/train',audio_extension='wav') -> None:\n",
    "        self.meta=None\n",
    "        self.transcription_path=transcription_path\n",
    "        self.audio_path=audio_path\n",
    "        self.audio_extension=audio_extension\n",
    "        self.file_to_trancscript={}\n",
    "        self.file_to_path={}\n",
    "    def load_transcription(self):\n",
    "        name_to_text = {}\n",
    "        try:\n",
    "            with open (self.transcription_path, encoding=\"utf-8\")as f:\n",
    "                f.readline()\n",
    "                for line in f:\n",
    "                    line=line.strip()\n",
    "                    ls=line.split(\"\\t\",1)\n",
    "                    name_to_text[ls[0]]=ls[1]\n",
    "            self.file_to_trancscript=name_to_text\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {self.transcription_path} couldn't be found\")\n",
    "        except Exception:\n",
    "            print(\"Error Occured\")\n",
    "            traceback.print_exc()\n",
    "        return name_to_text\n",
    "    def get_file_to_transcription(self):\n",
    "        return self.file_to_trancscript\n",
    "\n",
    "    def load_audio_file_paths(self):\n",
    "        dict={}\n",
    "        try:\n",
    "            files = librosa.util.find_files(self.audio_path, ext=self.audio_extension, recurse=True)\n",
    "            names = [os.path.splitext(os.path.basename(x))[0] for x in files]\n",
    "            for i in range(0,len(files)):\n",
    "                dict[names[i]]=os.path.relpath(files[i])\n",
    "            self.file_to_path=dict\n",
    "        except Exception:\n",
    "            print(\"Error Occured\")\n",
    "            traceback.print_exc()\n",
    "        return dict\n",
    "    def get_file_to_path(self):\n",
    "        return self.file_to_path\n",
    "    def meta_data(self): \n",
    "        target=[]\n",
    "        filenames=[]\n",
    "        paths=[]\n",
    "        duration_of_recordings=[]\n",
    "        channels=[]\n",
    "        sampleRates=[]\n",
    "        for i in self.file_to_trancscript:\n",
    "            try:\n",
    "                target.append(self.file_to_trancscript[i])\n",
    "                filenames.append(i)\n",
    "                paths.append(self.file_to_path[i])\n",
    "\n",
    "                audio, sampleRate = librosa.load(self.file_to_path[i],sr=None,mono=False)\n",
    "                sampleRates.append(sampleRate)\n",
    "                duration_of_recordings.append(float(audio.shape[0]/sampleRate))\n",
    "                channels.append(len(audio.shape))\n",
    "            except KeyError:\n",
    "                print(f\"Error occured couldn't find path for {i}\")\n",
    "                continue\n",
    "            except Exception:\n",
    "                print(f\"Error Occured for file {i}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "                \n",
    "                \n",
    "        data=pd.DataFrame({'file': filenames,'text': target,'path':paths,'sample_rate':sampleRates,\"channels\":channels, 'duration':duration_of_recordings})\n",
    "        self.meta=data\n",
    "        return data\n",
    "    def generate_meta_data(self):\n",
    "        self.load_audio_file_paths()\n",
    "        self.load_transcription()\n",
    "        self.meta_data()\n",
    "        return self.meta\n",
    "    def get_meta(self):\n",
    "        return self.meta\n",
    "    def meta_to_csv(self,path='meta.csv'):\n",
    "        self.meta.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b190e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta=MetaCreate()\n",
    "meta_data=meta.generate_meta_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ba0da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>path</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>channels</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
       "      <td>../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
       "      <td>../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
       "      <td>../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
       "      <td>../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>kule abidjan raia wa jiji hilo</td>\n",
       "      <td>../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "\n",
       "                                                text  \\\n",
       "0  yanayo andaliwa nami pendo pondo idhaa ya kisw...   \n",
       "1  inayokutangazia moja kwa moja kutoka jijini da...   \n",
       "2  juma hili bara la afrika limeshuhudia raia wa ...   \n",
       "3    wakipiga kura ya maoni ilikufanya mabadiliko ya   \n",
       "4                     kule abidjan raia wa jiji hilo   \n",
       "\n",
       "                                                path  sample_rate  channels  \\\n",
       "0  ../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...        16000         1   \n",
       "1  ../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...        16000         1   \n",
       "2  ../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...        16000         1   \n",
       "3  ../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...        16000         1   \n",
       "4  ../../../../Downloads/ALFFA_PUBLIC/ASR/SWAHILI...        16000         1   \n",
       "\n",
       "   duration  \n",
       "0      3.10  \n",
       "1      3.65  \n",
       "2      3.90  \n",
       "3      2.94  \n",
       "4      2.45  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b7a99",
   "metadata": {},
   "source": [
    "# Resize and Standardize #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df072f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to load audio file\n",
    "#specifying sample rate will resize all the files i.e Audio will be automatically resampled to the given rate\n",
    "class Loader:\n",
    "  def __init__(self, sample_rate,duration,mono):\n",
    "    self.sample_rate=sample_rate\n",
    "    self.duration=duration\n",
    "    self.mono=mono\n",
    "    self.channel = 2\n",
    "\n",
    "\n",
    "  def load(self,filepath):\n",
    "    sig, sr = torchaudio.load(filepath)\n",
    "    aud = sig, sr\n",
    "    return aud\n",
    "\n",
    "  #before using this function kindly change your file paths for it to work\n",
    "\n",
    "\n",
    "  def rechannel(self, aud):    #convert mono to stereo\n",
    "    # aud=self.aud\n",
    "    sig, sr = aud\n",
    "  \n",
    "\n",
    "    if (sig.shape[0] == self.channel):\n",
    "      # Nothing to do\n",
    "      return self.aud\n",
    "\n",
    "    if (self.channel == 1):\n",
    "      # Convert from stereo to mono by selecting only the first channel\n",
    "      resig = sig[:1, :]\n",
    "    else:\n",
    "      # Convert from mono to stereo by duplicating the first channel\n",
    "      resig = torch.cat([sig, sig])\n",
    "\n",
    "    aud = resig, sr\n",
    "  def resample(self,aud):                    #standardize sample rate\n",
    "    sig, sr = aud\n",
    "    \n",
    "    if (sr == self.sample_rate):\n",
    "      # Nothing to do\n",
    "      return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    # Resample first channel\n",
    "    resig = torchaudio.transforms.Resample(sr, self.sample_rate)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      # Resample the second channel and merge both channels\n",
    "      retwo = torchaudio.transforms.Resample(sr, self.sample_rate)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "      aud = resig, self.sample_rate\n",
    "    return aud\n",
    "\n",
    "  # ----------------------------\n",
    "  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
    "  # ----------------------------\n",
    "  def pad_trunc(self,aud):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * self.duration\n",
    "\n",
    "    if (sig_len > max_len):\n",
    "      # Truncate the signal to the given length\n",
    "      sig = sig[:,:max_len]\n",
    "\n",
    "    elif (sig_len < max_len):\n",
    "      # Length of padding to add at the beginning and end of the signal\n",
    "      pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "      pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "      # Pad with 0s\n",
    "      pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "      pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "      sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "      aud = sig, sr\n",
    "    return aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "  '''Processes audio files in a directory by applying the following steps\n",
    "    1. Load the data, convert to stereo and resample sampling rate\n",
    "    2. Pad the audio\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    self.padder=None\n",
    "    self._loader=None\n",
    "   \n",
    "\n",
    "  def process(self,audio_files_directory):\n",
    "    for root, directories, files in os.walk(audio_files_directory):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            self._process_file(filepath)\n",
    "            print(f\"Processed file {filepath}\")\n",
    "    \n",
    "  def _process_file(self,filepath):\n",
    "    signal=self.loader.load(filepath)\n",
    "    signal = self.loader.make_stereo(signal)\n",
    "    signal = self.loader.resample(signal)\n",
    "    signal= self.loader.pad_trunc(signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATION=4000\n",
    "SAMPLE_RATE=44100\n",
    "MONO=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33925d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=Loader(SAMPLE_RATE, DURATION, MONO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0495b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline=PreprocessingPipeline()\n",
    "preprocessing_pipeline.loader=loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline.process(Path_to_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
